{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep learning for Tabular Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tabular modeling takes data in table form. The goal is to estimate the value in one column based on the other column values. One example of Tabular data is the rossman store sales from https://www.kaggle.com/c/rossmann-store-sales/data. Where you are provided with historical sales data for 1,115 Rossmann stores. The task is to forecast the \"Sales\" column for the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the fields are self-explanatory.\n",
    "\n",
    "    Id - an Id that represents a (Store, Date) duple within the test set\n",
    "    Store - a unique Id for each store\n",
    "    Sales - the turnover for any given day (this is what you are predicting)\n",
    "    Customers - the number of customers on a given day\n",
    "    Open - an indicator for whether the store was open: 0 = closed, 1 = open\n",
    "    StateHoliday - indicates a state holiday. Normally all stores, with few exceptions, are closed on state holidays. Note that all schools are closed on public holidays and weekends. a = public holiday, b = Easter holiday, c = Christmas, 0 = None\n",
    "    SchoolHoliday - indicates if the (Store, Date) was affected by the closure of public schools\n",
    "    StoreType - differentiates between 4 different store models: a, b, c, d\n",
    "    Assortment - describes an assortment level: a = basic, b = extra, c = extended\n",
    "    CompetitionDistance - distance in meters to the nearest competitor store\n",
    "    CompetitionOpenSince[Month/Year] - gives the approximate year and month of the time the nearest competitor was opened\n",
    "    Promo - indicates whether a store is running a promo on that day\n",
    "    Promo2 - Promo2 is a continuing and consecutive promotion for some stores: 0 = store is not participating, 1 = store is participating\n",
    "    Promo2Since[Year/Week] - describes the year and calendar week when the store started participating in Promo2\n",
    "    PromoInterval - describes the consecutive intervals Promo2 is started, naming the months the promotion is started anew. E.g. \"Feb,May,Aug,Nov\" means each round starts in February, May, August, November of any given year for that store\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.3.1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from pandas.api.types import is_numeric_dtype, is_categorical_dtype\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "from sklearn.utils import column_or_1d\n",
    "from tqdm.notebook import trange,  tqdm\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data visualization and preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we first need to visualize and preprocess our data. Check if they have the proper type and handle the missing value if any."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use pandas to load and interact with our data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('train.csv', low_memory=False)\n",
    "n = len(data)\n",
    "idx = np.random.permutation(range(n))[:3000]\n",
    "idx.sort()\n",
    "data = data.iloc[idx[:3000]] # Let's only use a small portion of your data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`head()` is nice to look at the first few rows in a dataset and at the column names. This already gives us an intuition of what kind of data we can expect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>Date</th>\n",
       "      <th>Sales</th>\n",
       "      <th>Customers</th>\n",
       "      <th>Open</th>\n",
       "      <th>Promo</th>\n",
       "      <th>StateHoliday</th>\n",
       "      <th>SchoolHoliday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>316</td>\n",
       "      <td>5</td>\n",
       "      <td>2015-07-31</td>\n",
       "      <td>11678</td>\n",
       "      <td>927</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>557</td>\n",
       "      <td>5</td>\n",
       "      <td>2015-07-31</td>\n",
       "      <td>5417</td>\n",
       "      <td>752</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>760</th>\n",
       "      <td>761</td>\n",
       "      <td>5</td>\n",
       "      <td>2015-07-31</td>\n",
       "      <td>12761</td>\n",
       "      <td>1203</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>777</th>\n",
       "      <td>778</td>\n",
       "      <td>5</td>\n",
       "      <td>2015-07-31</td>\n",
       "      <td>7341</td>\n",
       "      <td>804</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>798</td>\n",
       "      <td>5</td>\n",
       "      <td>2015-07-31</td>\n",
       "      <td>9268</td>\n",
       "      <td>997</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Store  DayOfWeek        Date  Sales  Customers  Open  Promo StateHoliday  \\\n",
       "315    316          5  2015-07-31  11678        927     1      1            0   \n",
       "556    557          5  2015-07-31   5417        752     1      1            0   \n",
       "760    761          5  2015-07-31  12761       1203     1      1            0   \n",
       "777    778          5  2015-07-31   7341        804     1      1            0   \n",
       "797    798          5  2015-07-31   9268        997     1      1            0   \n",
       "\n",
       "     SchoolHoliday  \n",
       "315              1  \n",
       "556              1  \n",
       "760              1  \n",
       "777              0  \n",
       "797              1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This displays a few summary statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>Sales</th>\n",
       "      <th>Customers</th>\n",
       "      <th>Open</th>\n",
       "      <th>Promo</th>\n",
       "      <th>SchoolHoliday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>564.000000</td>\n",
       "      <td>3.961000</td>\n",
       "      <td>5778.641667</td>\n",
       "      <td>639.087000</td>\n",
       "      <td>0.830667</td>\n",
       "      <td>0.384667</td>\n",
       "      <td>0.179000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>320.077351</td>\n",
       "      <td>1.996866</td>\n",
       "      <td>3897.991649</td>\n",
       "      <td>477.320096</td>\n",
       "      <td>0.375109</td>\n",
       "      <td>0.486598</td>\n",
       "      <td>0.383416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>289.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3707.500000</td>\n",
       "      <td>399.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>569.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5709.500000</td>\n",
       "      <td>613.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>836.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>7812.500000</td>\n",
       "      <td>840.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1115.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>28682.000000</td>\n",
       "      <td>4394.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Store    DayOfWeek         Sales    Customers         Open  \\\n",
       "count  3000.000000  3000.000000   3000.000000  3000.000000  3000.000000   \n",
       "mean    564.000000     3.961000   5778.641667   639.087000     0.830667   \n",
       "std     320.077351     1.996866   3897.991649   477.320096     0.375109   \n",
       "min       1.000000     1.000000      0.000000     0.000000     0.000000   \n",
       "25%     289.000000     2.000000   3707.500000   399.000000     1.000000   \n",
       "50%     569.000000     4.000000   5709.500000   613.000000     1.000000   \n",
       "75%     836.000000     6.000000   7812.500000   840.000000     1.000000   \n",
       "max    1115.000000     7.000000  28682.000000  4394.000000     1.000000   \n",
       "\n",
       "             Promo  SchoolHoliday  \n",
       "count  3000.000000    3000.000000  \n",
       "mean      0.384667       0.179000  \n",
       "std       0.486598       0.383416  \n",
       "min       0.000000       0.000000  \n",
       "25%       0.000000       0.000000  \n",
       "50%       0.000000       0.000000  \n",
       "75%       1.000000       0.000000  \n",
       "max       1.000000       1.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This returns the data types of our columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Store             int64\n",
       "DayOfWeek         int64\n",
       "Date             object\n",
       "Sales             int64\n",
       "Customers         int64\n",
       "Open              int64\n",
       "Promo             int64\n",
       "StateHoliday     object\n",
       "SchoolHoliday     int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0', 'a', 'b', 'c'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.StateHoliday.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, some columns contain numerical data, others contain string values. The numerical data can be directly fed to our Neural Network (with some optional preprocessing), but other columns need to be converted to numbers. Since the values in those correspond to different categories, we often call these type of variables categorical variables. The first type are called continuous variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continuous variables\n",
    "are numerical data, such as \"age\" can be directly fed to the model, since you can add and multiply them directly. \n",
    "\n",
    "### Categorical variables\n",
    "contain a number of discrete levels, such as \"sex\", for which addition and multiplication don't have meaning (even if they're stored as numbers).\n",
    "Therefere this refers to input features that represent one or more discrete items from a finite set of choices. \n",
    "Categorical data is most efficiently represented via sparse tensors, which are tensors with very few non-zero elements.\n",
    "\n",
    "In order to use such representations within a machine learning system, we need a way to represent each sparse vector as a vector of numbers so that semantically similar items have similar distances in the vector space. But how do you represent a word as a vector of numbers?\n",
    "\n",
    "The simplest way is to define a giant input layer with a node for every word in your vocabulary, or at least a node for every word that appears in your data. If 500,000 unique words appear in your data, you could represent a word with a length 500,000 vector and assign each word to a slot in the vector.\n",
    "\n",
    "If you assign \"horse\" to index 1247, then to feed \"horse\" into your network you might copy a 1 into the 1247th input node and 0s into all the rest. This sort of representation is called a one-hot encoding, because only one index has a non-zero value.\n",
    "\n",
    "More typically your vector might contain counts of the words in a larger chunk of text. This is known as a \"bag of words\" representation. In a bag-of-words vector, several of the 500,000 nodes would have non-zero value.\n",
    "\n",
    "But however you determine the non-zero values, one-node-per-word gives you very sparse input vectors—very large vectors with relatively few non-zero values. Sparse representations have a couple of problems that can make it hard for a model to learn effectively.\n",
    "\n",
    "The solution to this problem is to use *embeddings*, which translate large sparse vectors into a lower-dimensional space that preserves semantic relationships. We'll explore embeddings intuitively, conceptually, and programmatically in the following sections of this module.\n",
    "\n",
    "\n",
    "### What is an embedding?\n",
    "\n",
    "\n",
    "An embedding is a relatively low-dimensional space into which you can translate high-dimensional vectors. \n",
    "In other word, It is a categorical feature represented as a continuous-valued feature. It can be also perseved as a translation of a high-dimensional vector into a low-dimensional space. For example, you can represent the words in an English sentence in either of the following two ways:\n",
    "\n",
    "    * As a million-element (high-dimensional) sparse vector in which all elements are integers. Each cell in the vector represents a separate English word; the value in a cell represents the number of times that word appears in a sentence. Since a single English sentence is unlikely to contain more than 50 words, nearly every cell in the vector will contain a 0. The few cells that aren't 0 will contain a low integer (usually 1) representing the number of times that word appeared in the sentence.\n",
    "    * As a several-hundred-element (low-dimensional) dense vector in which each element holds a floating-point value between 0 and 1. This is an embedding.\n",
    "\n",
    "Ideally, an embedding captures some of the semantics of the input by placing semantically similar inputs close together in the embedding space. An embedding can be learned and reused across models.\n",
    "\n",
    "\n",
    "\n",
    "A key technique to making the most of deep learning for tabular data is to use embeddings for your categorical variables. This approach allows for relationships between categories to be captured. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline\n",
    "A typical pipeline is as follow for tabular/ structured data:\n",
    "* Categorify\n",
    "* Fill missing value\n",
    "* Normalize Continious variable\n",
    "Those step are necessary in order to get good result with your model. This implementation is left to the reader as an exercice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that those variable represent categorical feature, therefore we transform them into categorical variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 4, 3, 2, 1, 7, 6])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.DayOfWeek.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Open.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Promo.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0', 'a', 'b', 'c'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.StateHoliday.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.SchoolHoliday.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.StateHoliday = data.StateHoliday.astype(str)\n",
    "data.SchoolHoliday = data.SchoolHoliday.astype(str)\n",
    "data.DayOfWeek = data.DayOfWeek.astype(str)\n",
    "data.Open  = data.Open.astype(str)\n",
    "data.Promo = data.Promo.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[data['StateHoliday'] == 0, 'StateHoliday'] = 'zero'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine categorical variables in our data and return their names and number of unique categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize(X):\n",
    "    '''\n",
    "    Determine categorical variables in X and return\n",
    "    their names and number of unique categories.\n",
    "    :param X: input DataFrame\n",
    "    :return: list of tuples\n",
    "    '''\n",
    "    cat_sz = [(col, X[col].unique().shape[0]) for col in X.columns\n",
    "              if X[col].dtype == 'object']\n",
    "\n",
    "    return cat_sz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('DayOfWeek', 7),\n",
       " ('Date', 908),\n",
       " ('Open', 2),\n",
       " ('Promo', 2),\n",
       " ('StateHoliday', 4),\n",
       " ('SchoolHoliday', 2)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_sz = categorize(data)\n",
    "cat_sz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine the embedding dimensions for categorical variables. If embedding dimensions are not provided, will use a rule of thumb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_emb_dim(cat_sz, max_dim=50, emb_dims=None, include_unseen=False):\n",
    "    '''\n",
    "    Determine the embedding dimensions for categorical variables.\n",
    "    If embedding dimensions are not provided, will use a rule of thumb.\n",
    "    :param cat_sz: list of tuples\n",
    "    :param max_dim: maximum embedding dimension\n",
    "    :param emb_dims: array-like of embedding dimensions,\n",
    "                     same length as cat_sz\n",
    "    :param include_unseen: optional, add extra category for 'unseen'\n",
    "    :return: dictionary of categorical variables for Embedder\n",
    "    '''\n",
    "    if emb_dims is None:\n",
    "        emb_sz = {var: (input_dim, min(max_dim, (input_dim + 1) // 2))\n",
    "                  for var, input_dim in cat_sz}\n",
    "    else:\n",
    "        emb_sz = {c[0]: (c[1], emb_dim)\n",
    "                  for c, emb_dim in zip(cat_sz, emb_dims)\n",
    "                  }\n",
    "\n",
    "    if include_unseen:\n",
    "        emb_sz = {var: (sz[0] + 1, sz[1]) for var, sz in emb_sz.items()}\n",
    "\n",
    "    return emb_sz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DayOfWeek': (7, 4),\n",
       " 'Date': (908, 50),\n",
       " 'Open': (2, 1),\n",
       " 'Promo': (2, 1),\n",
       " 'StateHoliday': (4, 2),\n",
       " 'SchoolHoliday': (2, 1)}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_sz = pick_emb_dim(cat_sz)\n",
    "emb_sz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's encode categorical variables as integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SafeLabelEncoder(LabelEncoder):\n",
    "    \"\"\"An extension of LabelEncoder that will\n",
    "    not throw an exception for unseen data, but will\n",
    "    instead return a default value of len(labels)\n",
    "    Attributes\n",
    "    ----------\n",
    "    classes_ : the classes that are encoded\n",
    "    \"\"\"\n",
    "\n",
    "    def transform(self, y):\n",
    "\n",
    "        check_is_fitted(self, 'classes_')\n",
    "        y = column_or_1d(y, warn=True)\n",
    "\n",
    "        unseen = len(self.classes_)\n",
    "\n",
    "        e = np.array([\n",
    "                     np.searchsorted(self.classes_, x)\n",
    "                     if x in self.classes_ else unseen\n",
    "                     for x in y\n",
    "                     ])\n",
    "\n",
    "        if unseen in e:\n",
    "            self.classes_ = np.array(self.classes_.tolist() + ['unseen'])\n",
    "\n",
    "        return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_categorical(X,\n",
    "                       categorical_vars=None,\n",
    "                       copy=True):\n",
    "    '''\n",
    "    Encode categorical variables as integers.\n",
    "    :param X: input DataFrame\n",
    "    :param categorical_vars: optional, list of categorical variables\n",
    "    :param copy: optional, whether to modify a copy\n",
    "    :return: DataFrame, LabelEncoders\n",
    "    '''\n",
    "    df = X.copy() if copy else X\n",
    "    encoders = {}\n",
    "\n",
    "    if categorical_vars is None:\n",
    "        categorical_vars = [col for col in df.columns\n",
    "                            if df[col].dtype == 'object']\n",
    "\n",
    "    for var in categorical_vars:\n",
    "        encoders[var] = SafeLabelEncoder()\n",
    "        encoders[var].fit(df[var])\n",
    "        df.loc[:, var] = encoders[var].transform(df.loc[:, var])\n",
    "\n",
    "    return df, encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, encoders = encode_categorical(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>Date</th>\n",
       "      <th>Sales</th>\n",
       "      <th>Customers</th>\n",
       "      <th>Open</th>\n",
       "      <th>Promo</th>\n",
       "      <th>StateHoliday</th>\n",
       "      <th>SchoolHoliday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>316</td>\n",
       "      <td>4</td>\n",
       "      <td>907</td>\n",
       "      <td>11678</td>\n",
       "      <td>927</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>557</td>\n",
       "      <td>4</td>\n",
       "      <td>907</td>\n",
       "      <td>5417</td>\n",
       "      <td>752</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>760</th>\n",
       "      <td>761</td>\n",
       "      <td>4</td>\n",
       "      <td>907</td>\n",
       "      <td>12761</td>\n",
       "      <td>1203</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>777</th>\n",
       "      <td>778</td>\n",
       "      <td>4</td>\n",
       "      <td>907</td>\n",
       "      <td>7341</td>\n",
       "      <td>804</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>798</td>\n",
       "      <td>4</td>\n",
       "      <td>907</td>\n",
       "      <td>9268</td>\n",
       "      <td>997</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1015700</th>\n",
       "      <td>721</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6353</td>\n",
       "      <td>760</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1015722</th>\n",
       "      <td>743</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3106</td>\n",
       "      <td>425</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1016001</th>\n",
       "      <td>1022</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5584</td>\n",
       "      <td>697</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1016465</th>\n",
       "      <td>371</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1016612</th>\n",
       "      <td>518</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Store  DayOfWeek  Date  Sales  Customers  Open  Promo  StateHoliday  \\\n",
       "315        316          4   907  11678        927     1      1             0   \n",
       "556        557          4   907   5417        752     1      1             0   \n",
       "760        761          4   907  12761       1203     1      1             0   \n",
       "777        778          4   907   7341        804     1      1             0   \n",
       "797        798          4   907   9268        997     1      1             0   \n",
       "...        ...        ...   ...    ...        ...   ...    ...           ...   \n",
       "1015700    721          2     1   6353        760     1      0             0   \n",
       "1015722    743          2     1   3106        425     1      0             0   \n",
       "1016001   1022          2     1   5584        697     1      0             0   \n",
       "1016465    371          1     0      0          0     0      0             1   \n",
       "1016612    518          1     0      0          0     0      0             1   \n",
       "\n",
       "         SchoolHoliday  \n",
       "315                  1  \n",
       "556                  1  \n",
       "760                  1  \n",
       "777                  0  \n",
       "797                  1  \n",
       "...                ...  \n",
       "1015700              1  \n",
       "1015722              1  \n",
       "1016001              1  \n",
       "1016465              1  \n",
       "1016612              1  \n",
       "\n",
       "[3000 rows x 9 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DayOfWeek': SafeLabelEncoder(),\n",
       " 'Date': SafeLabelEncoder(),\n",
       " 'Open': SafeLabelEncoder(),\n",
       " 'Promo': SafeLabelEncoder(),\n",
       " 'StateHoliday': SafeLabelEncoder(),\n",
       " 'SchoolHoliday': SafeLabelEncoder()}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List the name of column of your cateorical feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DayOfWeek', 'Date', 'Open', 'Promo', 'StateHoliday', 'SchoolHoliday']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_features = [c[0] for c in cat_sz]\n",
    "categorical_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_feature = \"Sales\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following implementation uses pytorch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our dataset drop the `Sales` column from the training set because it is the value we want to predict (dependent variable)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TabularDataset(Dataset):\n",
    "    def __init__(self, data, cat_cols=None, output_col=None):\n",
    "        \"\"\"\n",
    "        Characterizes a Dataset for PyTorch\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "\n",
    "        data: pandas data frame\n",
    "          The data frame object for the input data. It must\n",
    "          contain all the continuous, categorical and the\n",
    "          output columns to be used.\n",
    "\n",
    "        cat_cols: List of strings\n",
    "          The names of the categorical columns in the data.\n",
    "          These columns will be passed through the embedding\n",
    "          layers in the model. These columns must be\n",
    "          label encoded beforehand. \n",
    "\n",
    "        output_col: string\n",
    "          The name of the output variable column in the data\n",
    "          provided.\n",
    "        \"\"\"\n",
    "\n",
    "        self.n = data.shape[0]\n",
    "\n",
    "        if output_col:\n",
    "            self.y = data[output_col].astype(np.float32).values.reshape(-1, 1)\n",
    "        else:\n",
    "            self.y =  np.zeros((self.n, 1))\n",
    "\n",
    "        self.cat_cols = cat_cols if cat_cols else []\n",
    "        self.cont_cols = [col for col in data.columns\n",
    "                          if col not in self.cat_cols + [output_col]]\n",
    "\n",
    "        if self.cont_cols:\n",
    "            self.cont_X = data[self.cont_cols].astype(np.float32).values\n",
    "        else:\n",
    "            self.cont_X = np.zeros((self.n, 1))\n",
    "\n",
    "        if self.cat_cols:\n",
    "            self.cat_X = data[cat_cols].astype(np.int32).values\n",
    "        else:\n",
    "            self.cat_X =  np.zeros((self.n, 1))\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Denotes the total number of samples.\n",
    "        \"\"\"\n",
    "        return self.n\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Generates one sample of data.\n",
    "        \"\"\"\n",
    "        return [self.y[idx], self.cont_X[idx], self.cat_X[idx]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = TabularDataset(df, cat_cols=categorical_features, output_col=output_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([11678.], dtype=float32),\n",
       " array([316., 927.], dtype=float32),\n",
       " array([  4, 907,   1,   1,   0,   1], dtype=int32)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "class TabularModel(nn.Module):\n",
    "    \"Basic model for tabular data\"\n",
    "    \n",
    "    def __init__(self, emb_szs, n_cont, out_sz, layers, drops, y_range):\n",
    "        \"\"\"\n",
    "            Parameters\n",
    "            ----------\n",
    "\n",
    "            emb_szs: List of two element tuples\n",
    "              This list will contain a two element tuple for each\n",
    "              categorical feature. The first element of a tuple will\n",
    "              denote the number of unique values of the categorical\n",
    "              feature. The second element will denote the embedding\n",
    "              dimension to be used for that feature.\n",
    "\n",
    "            n_cont: Integer\n",
    "              The number of continuous features in the data.\n",
    "\n",
    "            layers: List of integers.\n",
    "              The size of each linear layer. The length will be equal\n",
    "              to the total number of linear layers in the network.\n",
    "\n",
    "            out_sz: Integer\n",
    "              The size of the final output.\n",
    "\n",
    "            drops: List of floats\n",
    "              The dropouts to be used after each linear layer.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.embeds = nn.ModuleList([nn.Embedding(ni, nf) for ni,nf in emb_szs])\n",
    "        self.bn_cont = nn.BatchNorm1d(n_cont)\n",
    "        n_emb = sum(e.embedding_dim for e in self.embeds)\n",
    "        self.n_emb,self.n_cont, self.y_range = n_emb,n_cont, y_range\n",
    "        final_act = None if y_range is None else nn.Sigmoid()\n",
    "        sizes = [n_emb + n_cont] + layers + [out_sz]\n",
    "        actns = [nn.ReLU(inplace=True)] * (len(sizes)-2) + [final_act]\n",
    "        layers = []\n",
    "        for i,(n_in,n_out,dp,act) in enumerate(zip(sizes[:-1],sizes[1:],[0.]+drops,actns)):\n",
    "            layers += nn.ModuleList([\n",
    "                    nn.BatchNorm1d(n_in), \n",
    "                    nn.Dropout(dp),\n",
    "                    nn.Linear(n_in, n_out),\n",
    "                    act\n",
    "            ])\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x_cat, x_cont):\n",
    "        if self.n_emb != 0:\n",
    "            x = [e(x_cat[:,i].long()) for i,e in enumerate(self.embeds)]\n",
    "            x = torch.cat(x, 1)\n",
    "        if self.n_cont != 0:\n",
    "            x_cont = self.bn_cont(x_cont)\n",
    "            x = torch.cat([x, x_cont], 1) if self.n_emb != 0 else x_cont\n",
    "        x = self.layers(x)\n",
    "        if self.y_range is not None: x = (self.y_range[1] - self.y_range[0]) * x + self.y_range[0]\n",
    "        return x.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_log_y = np.log(np.max(df['Sales']))\n",
    "y_range = torch.tensor([0, max_log_y*1.2]).float().to(torch.device(\"cuda:1\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train our network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "from torch.nn import functional as F\n",
    "lr = 1e-3\n",
    "epochs = 10\n",
    "bs = 64\n",
    "device = torch.device(\"cuda:1\")\n",
    "train_dl = DataLoader(ds, batch_size=bs, shuffle=True, num_workers=1)\n",
    "model = TabularModel(emb_szs=[e for i,e in emb_sz.items()], n_cont=len(ds.cont_cols), out_sz=1, layers=[1000,500], drops=[0.001,0.01], y_range=y_range).to(device)\n",
    "opt = optim.SGD(model.parameters(), lr=lr)\n",
    "loss_func = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the topology of our network. As we can see each categorical variable has its own embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TabularModel(\n",
       "  (embeds): ModuleList(\n",
       "    (0): Embedding(7, 4)\n",
       "    (1): Embedding(908, 50)\n",
       "    (2): Embedding(2, 1)\n",
       "    (3): Embedding(2, 1)\n",
       "    (4): Embedding(4, 2)\n",
       "    (5): Embedding(2, 1)\n",
       "  )\n",
       "  (bn_cont): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (layers): Sequential(\n",
       "    (0): BatchNorm1d(61, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (1): Dropout(p=0.0, inplace=False)\n",
       "    (2): Linear(in_features=61, out_features=1000, bias=True)\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): Dropout(p=0.001, inplace=False)\n",
       "    (6): Linear(in_features=1000, out_features=500, bias=True)\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (9): Dropout(p=0.01, inplace=False)\n",
       "    (10): Linear(in_features=500, out_features=1, bias=True)\n",
       "    (11): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09bae1a9047742c2b02f442acd579923",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(56245004., device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "tensor(36936156., device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "tensor(48797868., device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "tensor(51558412., device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "tensor(50960380., device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "tensor(33605044., device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "tensor(50288356., device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "tensor(59564748., device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "tensor(50550820., device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "tensor(59472228., device='cuda:1', grad_fn=<MseLossBackward>)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in tqdm(range(epochs)):\n",
    "    for y, x_cont, x_cat  in train_dl:\n",
    "        \n",
    "        y = y.to(device)\n",
    "        x_cat = x_cat.to(device)\n",
    "        x_cont = x_cont.to(device)\n",
    "        # Forward Pass\n",
    "        pred = model(x_cat, x_cont)\n",
    "        loss = loss_func(pred, y)\n",
    "        \n",
    "        # Backward Pass and Optimization\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Improve our result by using a proper data preprocessing pipeline (Normalizing, etc)\n",
    "* Plot the embedding result\n",
    "* Implement the model on other problem for predicting categorical feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Wide & Deep Learning for Recommender Systems https://arxiv.org/abs/1606.07792\n",
    "* Entity Embeddings of Categorical Variables https://arxiv.org/abs/1604.06737\n",
    "* Artificial Neural Networks Applied to Taxi Destination Prediction https://arxiv.org/abs/1508.00021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* https://www.manning.com/books/deep-learning-with-structured-data\n",
    "* https://towardsdatascience.com/the-right-way-to-use-deep-learning-for-tabular-data-entity-embedding-b5c4aaf1423a\n",
    "* https://towardsdatascience.com/structured-deep-learning-b8ca4138b848\n",
    "* https://towardsdatascience.com/deep-learning-structured-data-8d6a278f3088\n",
    "* https://medium.com/@markryan_69718/deep-learning-on-structured-data-part-1-7f08584b9883"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
