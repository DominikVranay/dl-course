{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qSfEEb68rae4"
      },
      "source": [
        "# Konvolučné neurónové siete - LeNet\n",
        "\n",
        "Na dnešnom cvičení naimplementujeme jeden zo základných konvolučných neurónových sietí, konkrétne LeNet. Naše riešenie budeme aplikovať na rozpoznávanie rukou písaných číslic z datasetu MNIST. LeNet bol pôvodne navrhnutý v roku 1989 pre rozpoznávanie číslic amerických PSČ. Sieť následne prešla niekoľkými iteráciami a v roku 1998 bol [publikovaný model lenet-5](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=726791), ktorý bol presnejší ako bežné modely počítačového videnia na rozpoznávanie rukou písaných číslic. LeNet bol takisto medzi prvými konvolučnými sieťami, ktoré používali algoritmus spätného šírenia chyby na trénovanie. V našom riešení urobíme niekoľko zmien oproti pôvodnému článku, najmä čo sa týka použitej aktivačnej funkcie (pôvodne `tanh`) a optimalizátora (pôvodne jednoduchý `SGD`).\n",
        "\n",
        "Predpokladom na úspešné zvládnutie tohto cvičenia je pripravené programátorské prostredie s `tensorflow`om a `keras`om. Ak dané nástroje ste si ešte nenainštalovali, urobte tak podľa [tohto návodu](https://github.com/ianmagyar/dl-course/blob/master/labs/00%20-%20Setting-up-tensorflow.md). V priebehu cvičenia sa takisto oboznámime so základnými krokmi pri trénovaní hlbokých neurónových sietí.\n",
        "\n",
        "Kostru riešenia nájdete [tu](resources/lab04/lab04.py) alebo môžete pracovať priamo v tomto jupyter notebooku."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y8Xh44PLrafD"
      },
      "source": [
        "## 1. Načítanie potrebných knižníc\n",
        "\n",
        "V prvom kroku načítame všetky potrebné moduly pre definovanie, trénovanie a vyhodnotenie siete. Dokumentáciu príslušných tried a metód nájdete [tu pre keras](https://keras.io/api/) a [tu pre scikit-learn](https://scikit-learn.org/stable/modules/classes.html#sklearn-metrics-metrics)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "soeFKPBHrafE"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, Dense, Flatten, MaxPooling2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mMF_uaAerafG"
      },
      "source": [
        "## 2. Predspracovanie údajov\n",
        "\n",
        "Prvým dôležitým krokom pri vývoja hlbokých riešení je načítanie a predspracovanie datasetu. Samotné predpsracovanie v sebe zahŕňa hneď niekoľko úloh, ako výber príznakov, normalizácia hodnôt, vektorizácia vstupov a výstupov alebo rozdelenie datasetu na trénovaciu a testovaciu (prípadne validačnú) množinu.\n",
        "\n",
        "V skripte nájdete príkaz na načítanie datasetu MNIST, ktorý obsahuje čiernobiele obrázky rukou písaných číslic (viď nižšie) od 0 po 9. Dataset vieme načítať priamo z knižnice `keras` cez funkciu `load_data`. Pomocné premenné `img_height` a `img_width` obsahujú rozmery každého obrázka a slúžia pre opätovné použitie týchto hodnôt neskôr v kóde.\n",
        "\n",
        "![MNIST dataset](https://miro.medium.com/max/495/0*94t_5cPF9mvBj20z.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "8UHMWduNrafH"
      },
      "outputs": [],
      "source": [
        "# we load the dataset from keras\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# we set the image sizes for further use\n",
        "img_height, img_width = 28, 28"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZEFE5wVLrafH"
      },
      "source": [
        "Ako vidíte v kóde, pri načítaní datasetu hneď ho rozdelíme aj na trénovaciu a testovaciu množinu.\n",
        "\n",
        "Ďalším krokom je normalizácia hodnôt. V prvom rade potrebujeme vstupné čísla reprezentujúce pixely normalizovať na interval 0-1 a ešte je potrebné upraviť dimenzionalitu `numpy` polí, ktoré obsahujú vstupné dáta. Polia `x_train` a `x_test` rozšírime o jednu dimenziu s rozmerom 1, teda každú hodnotu \"zabalíme\" do wrappera, aby sa nám s nimi lepšie pracovalo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "VcT55mbzrafK"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "# reshape the training and testing input sets - add a channel\n",
        "# normalize input data to interval 0 - 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rREmDqeurafP"
      },
      "source": [
        "Výstupné dáta `y_train` a `y_test` majú formu poľa celých čísel od 0 po 9 (reprezentujúce číslice), keďže ale neriešime regresiu ale klasifikáciu, potrebujeme ich pretransformovať do podoby vektorov. Táto vektorová reprezentácia sa používa veľmi často pri spracovaní kategórií a reťazcov neurónovými sieťami. Na programovú realizáciu existuje niekoľko možností, my dnes použijeme funkciu `to_categorical` z knižnice `keras` ([dokumentácia](https://keras.io/api/utils/python_utils/#to_categorical-function))."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KE5dwG6frafQ"
      },
      "outputs": [],
      "source": [
        "# normalize (vectorize) output data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hVBlxuL5rafS"
      },
      "source": [
        "**Poznámka:** v niektorých prípadoch dokážete reťazce nahradiť jednoduchými číslami, takýto spôsob ale predpokladá, že čísla, ktoré sú blízko sebe vyjadrujú koncepty, ktoré sú veľmi podobné. Napríklad, ak máme stĺpec s hodnotami *low*, *middle*, *high*, tieto hodnoty vieme nahradiť číslami 1, 2 a 3. Rovnaký spôsob ale nemôžeme použiť s hodnotami napríklad značky auta: *Škoda* (1), *Audi* (2), *Lada* (3), pretože neurónová sieť by predpokladala, že Lada (3) je viac podobná Audi (2) ako Škodovke (1)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FxmlcndBrafT"
      },
      "source": [
        "## 3. Definícia modelu\n",
        "\n",
        "Našu hlbokú sieť zadefinujeme pomocou knižnice `keras`, ktorá ponúka vysokoúrovňové API na prácu s neurónovými sieťami. Na vytvorenie modelov máme dve možnosti: najprv vytvoríme objekt modelu a postupne doňho pridávame vrstvy, alebo najprv zadefinujeme a pospájame vrstvy a následne zadefinujeme model pomocou vstupnej a výstupnej vrstvy. Na cvičení použijeme prvý spôsob, sekvenčný model už máte v kóde vytvorený ([dokumentácia](https://keras.io/api/models/sequential/#sequential-class)). Pridajte do tohto modelu vrstvy podľa diagramu nižšie. V konvolučných a plne prepojených vrstvách použite aktiváciu `relu` a vo výstupnej vrstve `softmax`. Konvolučné kernely majú rozmer *5x5*, *pooling* kernely *2x2*.\n",
        "\n",
        "![](resources/lab04/lenet-structure.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "ue5u4iayrafT"
      },
      "outputs": [],
      "source": [
        "# define model, add layers based on the diagram\n",
        "model = Sequential()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23ewYdt2rafU"
      },
      "source": [
        "Vašu implementáciu si môžete skontrolovať pomocou funkcie `summary` ([dokumentácia](https://keras.io/api/models/model/#summary-method))."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s4fyFic-rafU"
      },
      "outputs": [],
      "source": [
        "# check the model structure\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "psfy5eC2rafV"
      },
      "source": [
        "Veľkým rozdielom medzi `tensorflow`om a `pytorch`om je potreba modely skompilovať pred trénovaním. Slúži na to metóda `compile` ([dokumentácia](https://keras.io/api/models/model_training_apis/#compile-method)). Pomocou nej **skompilujte model zadaním parametrov nasledovne**:\n",
        "\n",
        "- chybová funkcia - *categorical crossentropy*\n",
        "- optimalizátor - *Adam*\n",
        "- metriky - presnosť (*accuracy*)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NFfD7nPurafV"
      },
      "outputs": [],
      "source": [
        "# compile the model\n",
        "model.compile()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1cpmObvorafW"
      },
      "source": [
        "## 4. Trénovanie modelu\n",
        "\n",
        "Po skompilovaní modelu ho môžeme natrénovať, na čo slúži metóda `fit` ([dokumentácia](https://keras.io/api/models/model_training_apis/#fit-method)). Jej hlavné parametre sú:\n",
        "\n",
        "- trénovací vstup\n",
        "- trénovací výstup\n",
        "- `epochs` - počet epoch\n",
        "- `batch_size` - počet príkladov v jednej dávke (pred aktualizáciou parametrov)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CPPeaBo_rafW"
      },
      "outputs": [],
      "source": [
        "# train the network\n",
        "model.fit()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vzSkaoRHrafW"
      },
      "source": [
        "## 5. Vyhodnotenie siete\n",
        "\n",
        "Vyhodnotenie siete pozostáva z dvoch základných úloh: testovanie a vyhodnotenie. Pre testovanie musíme získať výstupy k vstupným hodnotám z trénovacej množiny pomocou metódy `predict` ([dokumentácia](https://keras.io/api/models/model_training_apis/#predict-method)). Alternatívne môžete na jednoduché vyhodnotenie použiť metódu `evaluate` ([dokumentácia](https://keras.io/api/models/model_training_apis/#evaluate-method))."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VwPleG9drafW"
      },
      "outputs": [],
      "source": [
        "y_pred = model.predict(x_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GCtf6yMprafX"
      },
      "source": [
        "Ďalej porovnáme ozajstné výstupy s očakávanými. Keďže výstup má vektorovú reprezentáciu, potrebujeme zistiť pozíciu kde sa nachádza najväčšia hodnota vo vektore. V tomto nám pomôže knižnica `numpy`, ktorú sme zatiaľ nepoužili explicitne, ale podporuje všetky už použité knižnice. Jedná sa o efektívne a optimalizované riešenie práce s poľami.\n",
        "\n",
        "Pre vyhodnotenie našej siete použijeme konfúznu maticu. Konfúzna matica je tabuľková reprezentácia, kde v riadkoch máme očakávané triedy a v stĺpcoch vypočítané (predikované). V bunkách tabuľky sú uložené počty príkladov klasifikované v danej kombinácii očakávanej a predikovanej triedy. Ideálny klasifikátor bude mať všetky hodnoty po hlavnej diagonále (ďalšie informácie nájdete na [wikipédii](https://en.wikipedia.org/wiki/Confusion_matrix))."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v7TdnEfXrafX"
      },
      "outputs": [],
      "source": [
        "y_test_class = np.argmax(y_test,axis=1)\n",
        "y_pred_class = np.argmax(y_pred,axis=1)\n",
        "\n",
        "print(confusion_matrix(y_test_class, y_pred_class))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_rO1hSFrrafX"
      },
      "source": [
        "Z konfúznej matici potom vieme vypočítať ďalšie metriky, ako presnosť (*accuracy*), návratnosť (*recall*) a precizita (*precision*):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_wJRFTTkrafY"
      },
      "outputs": [],
      "source": [
        "print(classification_report(y_test_class, y_pred_class))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ctm6-PhUrafY"
      },
      "source": [
        "Presnosť popisuje samotný klasifikátor a vypočíta sa nasledovne:\n",
        "\n",
        "$ACC = \\frac{TP + TN}{P + N}$\n",
        "\n",
        "kde $TP + TN$ je suma správne klasifikovaných príkladov (na hlavnej diagonále) a $P + N$ je počet všetkých príkladov.\n",
        "\n",
        "Návratnosť a precizita popisujú klasifikátor pre danú triedu, vypočítajú sa nasledovne:\n",
        "\n",
        "$REC = \\frac{TP}{P}$\n",
        "\n",
        "$PREC = \\frac{TP}{TP + FP}$\n",
        "\n",
        "kde $TP$ je počet správne klasifikovaných príkladov z danej triedy, $P$ je počet príkadov z danej triedy v testovacej množine a $FP$ je počet príkladov z testovacej množiny nesprávne klasifikovaných do tejto triedy.\n",
        "\n",
        "Metóda `classification_report` vypočíta ešte hodnotu F1, ktorá je harmonický priemer návratnosti a precizity:\n",
        "\n",
        "$F1 = 2 \\cdot \\frac{REC \\cdot PREC}{REC + PREC}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QBwcF-FkrafY"
      },
      "source": [
        "## Doplňujúce úlohy\n",
        "\n",
        "1. Originálny model LeNet používal aktivačnú funkciu `tanh` a trénovanie pomocou jednoduchého backpropagation (*stochastic gradient descent*). Upravte váš model a porovnajte presnosť dvoch modelov.\n",
        "2. Pri trénovaní sa často používa aj validačná množina, ktorá slúži na určenie včasného ukončenia trénovania a aby sme tak predišli pretrénovaniu modelu. Rozšírte vaše riešenie o použitie validačnej množiny."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t8f1tZpGrafZ"
      },
      "source": [
        "## Použité zdroje\n",
        "\n",
        "- [LeCun, Yann, Léon Bottou, Yoshua Bengio, and Patrick Haffner. \"Gradient-based learning applied to document recognition.\" Proceedings of the IEEE 86, no. 11 (1998): 2278-2324.](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=726791&tag=1)\n",
        "- [LeNet on MNIST with Keras and Tensorflow in Python](https://github.com/matthewrenze/lenet-on-mnist-with-keras-and-tensorflow-in-python)\n",
        "- [TensorSpace Playground - LeNet](https://tensorspace.org/html/playground/lenet.html)\n",
        "- [Ukážka vizualizácie konvolučných sietí](lab04b-cnn-visualization.ipynb)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
